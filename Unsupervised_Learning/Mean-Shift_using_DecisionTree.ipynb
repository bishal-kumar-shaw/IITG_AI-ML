{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code For Building Hybrid Classification Tree with 2-Means clustering in each Decision Node and Majority Voting in the Leaf Nodes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import errno\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-----node index\n",
      "None-------node Label\n",
      "0------node Depth\n",
      "455----- no. of datapoints\n",
      "0.6561495382219855-------- Impurity\n",
      "--------------\n",
      "1-----node index\n",
      "None-------node Label\n",
      "1------node Depth\n",
      "369----- no. of datapoints\n",
      "0.5228306721207346-------- Impurity\n",
      "--------------\n",
      "2\n",
      "label-0.0\n",
      "depth-1\n",
      "point_count-86\n",
      "impurity--0.0\n",
      "----------------------\n",
      "3-----node index\n",
      "None-------node Label\n",
      "2------node Depth\n",
      "223----- no. of datapoints\n",
      "0.12381624440340101-------- Impurity\n",
      "--------------\n",
      "4-----node index\n",
      "None-------node Label\n",
      "2------node Depth\n",
      "146----- no. of datapoints\n",
      "0.693053351391456-------- Impurity\n",
      "--------------\n",
      "5\n",
      "label-1.0\n",
      "depth-3\n",
      "point_count-80\n",
      "impurity--0.0\n",
      "----------------------\n",
      "6-----node index\n",
      "None-------node Label\n",
      "3------node Depth\n",
      "143----- no. of datapoints\n",
      "0.17411775156185527-------- Impurity\n",
      "--------------\n",
      "7-----node index\n",
      "None-------node Label\n",
      "3------node Depth\n",
      "44----- no. of datapoints\n",
      "0.3540511393449268-------- Impurity\n",
      "--------------\n",
      "8-----node index\n",
      "None-------node Label\n",
      "3------node Depth\n",
      "102----- no. of datapoints\n",
      "0.6430945029771711-------- Impurity\n",
      "--------------\n",
      "9-----node index\n",
      "None-------node Label\n",
      "4------node Depth\n",
      "64----- no. of datapoints\n",
      "0.18920898053816695-------- Impurity\n",
      "--------------\n",
      "10-----node index\n",
      "None-------node Label\n",
      "4------node Depth\n",
      "79----- no. of datapoints\n",
      "0.16145328629277475-------- Impurity\n",
      "--------------\n",
      "11\n",
      "label-0.0\n",
      "depth-4\n",
      "point_count-19\n",
      "impurity-0.20619205063323187\n",
      "----------------------\n",
      "12\n",
      "label-0.0\n",
      "depth-4\n",
      "point_count-25\n",
      "impurity-0.439669879401343\n",
      "----------------------\n",
      "13-----node index\n",
      "None-------node Label\n",
      "4------node Depth\n",
      "51----- no. of datapoints\n",
      "0.5455945739691843-------- Impurity\n",
      "--------------\n",
      "14-----node index\n",
      "None-------node Label\n",
      "4------node Depth\n",
      "51----- no. of datapoints\n",
      "0.6883336081894993-------- Impurity\n",
      "--------------\n",
      "15\n",
      "label-1.0\n",
      "depth-5\n",
      "point_count-30\n",
      "impurity-0.3250829733914482\n",
      "----------------------\n",
      "16\n",
      "label-1.0\n",
      "depth-5\n",
      "point_count-34\n",
      "impurity--0.0\n",
      "----------------------\n",
      "17\n",
      "label-1.0\n",
      "depth-5\n",
      "point_count-45\n",
      "impurity-0.18182028230491803\n",
      "----------------------\n",
      "18\n",
      "label-1.0\n",
      "depth-5\n",
      "point_count-34\n",
      "impurity-0.13269142083987176\n",
      "----------------------\n",
      "19\n",
      "label-0.0\n",
      "depth-5\n",
      "point_count-10\n",
      "impurity-0.5004024235381879\n",
      "----------------------\n",
      "20\n",
      "label-1.0\n",
      "depth-5\n",
      "point_count-41\n",
      "impurity-0.3196905981112379\n",
      "----------------------\n",
      "21\n",
      "label-0.0\n",
      "depth-5\n",
      "point_count-16\n",
      "impurity-0.6210863745552451\n",
      "----------------------\n",
      "22\n",
      "label-1.0\n",
      "depth-5\n",
      "point_count-35\n",
      "impurity-0.6429124396658009\n",
      "----------------------\n",
      "Tree Model Trained!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "class C_Node:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.m_NodeIndx=-1\n",
    "        self.m_Impurity=-1\n",
    "        self.m_NodeDepth=-1\n",
    "        self.m_ParentNodeIndx=-1\n",
    "        self.m_LeftChildIndx=-1\n",
    "        self.m_RightChildIndx=-1\n",
    "        self.m_IsDecisionNode=None\n",
    "        self.m_Label=-1\n",
    "        self.m_Centroids=None\n",
    "        self.m_LeftVar = None\n",
    "        self.m_RightVar = None\n",
    "        self.m_DataLength=None\n",
    "        \n",
    "    def setNode(self,nodeIndx,nodeDepth,parentNodeIndx):  \n",
    "        self.m_NodeIndx = nodeIndx\n",
    "        self.m_NodeDepth = nodeDepth\n",
    "        self.m_ParentNodeIndx = parentNodeIndx\n",
    "\n",
    "class C_Tree:\n",
    "    \n",
    "    def __init__(self,maxDepth,maxNodeNum,path,dataNumThresh,impThresh,ImpDropThresh,method):\n",
    "        self.m_MaxDepth = maxDepth\n",
    "        self.m_MaxNodeNum = maxNodeNum\n",
    "        self.m_CurrNodeNum = 0 \n",
    "        self.m_NodeArray = [C_Node() for i in range(self.m_MaxNodeNum)]\n",
    "        self.m_Path = path\n",
    "        self.m_DataNumThresh = dataNumThresh\n",
    "        self.m_ImpThresh = impThresh\n",
    "        self.m_ImpDropThresh = ImpDropThresh\n",
    "        self.m_Method = method\n",
    "        \n",
    "    def getImpurity(self,dataFileName):\n",
    "        datalist = np.genfromtxt(dataFileName, delimiter=',')\n",
    "        if (len(datalist.shape) == 1):\n",
    "            return 0\n",
    "        else:\n",
    "            y=np.array([int(i) for i in datalist[:,-1]])\n",
    "            label, label_count = np.unique(y, return_counts=True)\n",
    "            label_prob = label_count/np.sum(label_count,dtype=np.float64)\n",
    "\n",
    "            if self.m_Method==1:                                       ##Mis-classification Impurity\n",
    "                if len(label_prob)==1:\n",
    "                    imp = 0\n",
    "                else:\n",
    "                    imp = 1 - max(label_prob)\n",
    "\n",
    "            if self.m_Method==2:                                        ##Gini Impurity\n",
    "                imp = 1 - (np.sum(label_prob**2)) \n",
    "\n",
    "            if self.m_Method==3:                                        ##Entropy Impurity\n",
    "                if (len(label_count)==0) :\n",
    "                    imp = 0\n",
    "\n",
    "                else:\n",
    "                    imp = -1 * np.sum(np.array([p*np.log(p) for p in label_prob]))\n",
    "            return(imp)\n",
    "    \n",
    "    def informationDrop(self,data_left,data_right):    \n",
    "        filename1 = \"LeftFile.csv\"\n",
    "        filename2 = \"RightFile.csv\"\n",
    "        np.savetxt(filename1, data_left, delimiter = \",\")\n",
    "        np.savetxt(filename2, data_right, delimiter = \",\")\n",
    "        imp_left = self.getImpurity(filename1)\n",
    "        imp_right = self.getImpurity(filename2)\n",
    "        l = len(data_left)\n",
    "        r = len(data_right)\n",
    "        totalImp = (l*imp_left + r*imp_right)/(l+r)\n",
    "        return totalImp\n",
    "\n",
    "    def twoMeans(self,dataFileName):\n",
    "        datalist = np.genfromtxt(dataFileName, delimiter=',')\n",
    "        X = datalist[:,:datalist.shape[1]-1]\n",
    "        y = np.array([int(i) for i in datalist[:,-1]])\n",
    "        label, label_count = np.unique(y, return_counts=True)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=2).fit(X)\n",
    "        centroids = kmeans.cluster_centers_\n",
    "        cluster_labels = kmeans.labels_\n",
    "\n",
    "        data_left=[]\n",
    "        data_right=[]\n",
    "        label, label_count = np.unique(cluster_labels, return_counts=True)\n",
    "        for i in range(len(X)):\n",
    "            if cluster_labels[i]==label[0]:\n",
    "                data_left.append(datalist[i])\n",
    "            if cluster_labels[i]==label[1]:\n",
    "                data_right.append(datalist[i])     \n",
    "        data_left=np.array(data_left)\n",
    "        data_right=np.array(data_right)\n",
    "        return data_left,data_right,centroids\n",
    "\n",
    "    def decisionRule(self,x,node):\n",
    "        mean1 = node.m_Centroids[0]\n",
    "        mean2 = node.m_Centroids[1]\n",
    "        dist1 = np.linalg.norm(x-mean1)\n",
    "        dist2 = np.linalg.norm(x-mean2)\n",
    "        if dist1 <= dist2:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    def splitDataFile(self,node_obj,data_left,data_right):  \n",
    "        filename1 = self.m_Path+\"/\"+\"d_\"+str(node_obj.m_LeftChildIndx)+\".csv\"\n",
    "        filename2 = self.m_Path+\"/\"+\"d_\"+str(node_obj.m_RightChildIndx)+\".csv\"\n",
    "        os.makedirs(os.path.dirname(filename1), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(filename2), exist_ok=True)\n",
    "        np.savetxt(filename1, data_left, delimiter = \",\")\n",
    "        np.savetxt(filename2, data_right, delimiter = \",\")                                               \n",
    "    \n",
    "    def checkTerminationCondition(self,node,datafilename):\n",
    "        datalist = np.genfromtxt(datafilename, delimiter=',')\n",
    "        if len(datalist.shape) == 1:\n",
    "            IsDecisionNode = False\n",
    "            dataLength = 1\n",
    "            Label = datalist[-1]\n",
    "            imp = 0\n",
    "        else:    \n",
    "            dataLength = datalist.shape[0]\n",
    "            X = datalist[:,:-1]\n",
    "            y = datalist[:,-1]\n",
    "            label,label_count = np.unique(y,return_counts=True)\n",
    "            imp = self.getImpurity(datafilename)\n",
    "\n",
    "            data_left,data_right,centroids = self.twoMeans(datafilename)\n",
    "\n",
    "            InformationGain = imp - self.informationDrop(data_left,data_right)\n",
    "            if (dataLength<=self.m_DataNumThresh or imp<=self.m_ImpThresh or node.m_NodeDepth >= self.m_MaxDepth\n",
    "                or InformationGain <= self.m_ImpDropThresh):        \n",
    "\n",
    "                IsDecisionNode=False\n",
    "                Label = label[np.argmax(label_count)]\n",
    "            else:\n",
    "                IsDecisionNode=True\n",
    "                Label = None\n",
    "\n",
    "        return IsDecisionNode,dataLength,Label,imp,data_left,data_right,centroids\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        train_data = np.hstack((X_train,np.matrix(y_train).T))\n",
    "        fileName = self.m_Path+\"/\"+\"d_0.csv\"\n",
    "        train_data = pd.DataFrame(train_data)\n",
    "        train_data.to_csv(fileName,index=False,header=False )\n",
    "        \n",
    "        self.m_NodeArray[0].setNode(0,0,-1)   # Setting Root Node of the Tree\n",
    "        self.m_CurrNodeNum = self.m_CurrNodeNum+1\n",
    "\n",
    "        for nodeCount in range(self.m_MaxNodeNum): \n",
    "\n",
    "            if (self.m_NodeArray[nodeCount].m_NodeIndx==nodeCount and \n",
    "                self.m_NodeArray[nodeCount].m_LeftChildIndx==-1 and \n",
    "                self.m_NodeArray[nodeCount].m_RightChildIndx==-1 and \n",
    "                self.m_NodeArray[nodeCount].m_NodeDepth>=0):\n",
    "\n",
    "                    dataFileName = self.m_Path+\"/\"+\"d_\"+str(self.m_NodeArray[nodeCount].m_NodeIndx)+\".csv\" \n",
    "\n",
    "                    isDecisionNode,dataPointNum,label,impurity,data_left,data_right,centroids = self.checkTerminationCondition(\n",
    "                        self.m_NodeArray[nodeCount],dataFileName)\n",
    "\n",
    "                    self.m_NodeArray[nodeCount].m_DataLength = dataPointNum\n",
    "                    self.m_NodeArray[nodeCount].m_Impurity = impurity\n",
    "                    self.m_NodeArray[nodeCount].m_Label = label\n",
    "                    self.m_NodeArray[nodeCount].m_Centroids = centroids\n",
    "                    self.m_NodeArray[nodeCount].m_LeftVar = np.var(data_left[:,:-1],axis=0)\n",
    "                    self.m_NodeArray[nodeCount].m_RightVar = np.var(data_right[:,:-1],axis=0)\n",
    "                    if isDecisionNode==False:\n",
    "                        self.m_NodeArray[nodeCount].m_IsDecisionNode=False\n",
    "                        print(nodeCount)\n",
    "                        print(\"label-\"+str(self.m_NodeArray[nodeCount].m_Label))\n",
    "                        print(\"depth-\"+str(self.m_NodeArray[nodeCount].m_NodeDepth))\n",
    "                        print(\"point_count-\"+str(dataPointNum))\n",
    "                        print(\"impurity-\"+str(impurity))\n",
    "                        print(\"----------------------\")\n",
    "\n",
    "                    if isDecisionNode==True:\n",
    "                        self.m_NodeArray[nodeCount].m_IsDecisionNode=True\n",
    "                        self.m_NodeArray[nodeCount].m_LeftChildIndx=self.m_CurrNodeNum\n",
    "                        self.m_NodeArray[nodeCount].m_RightChildIndx=self.m_CurrNodeNum+1\n",
    "                        lci = self.m_CurrNodeNum\n",
    "                        rci = self.m_CurrNodeNum+1\n",
    "                        print(str(self.m_NodeArray[nodeCount].m_NodeIndx)+\"-----node index\")\n",
    "                        print(str(self.m_NodeArray[nodeCount].m_Label)+\"-------node Label\")\n",
    "                        print(str(self.m_NodeArray[nodeCount].m_NodeDepth)+\"------node Depth\")\n",
    "                        print(str(dataPointNum)+\"----- no. of datapoints\")\n",
    "                        print(str(impurity)+\"-------- Impurity\")\n",
    "                        print(\"--------------\")\n",
    "                        self.m_NodeArray[lci].setNode(lci,self.m_NodeArray[nodeCount].m_NodeDepth+1,\n",
    "                                self.m_NodeArray[nodeCount].m_NodeIndx)\n",
    "\n",
    "                        self.m_NodeArray[rci].setNode(rci,self.m_NodeArray[nodeCount].m_NodeDepth+1,\n",
    "                                self.m_NodeArray[nodeCount].m_NodeIndx)\n",
    "\n",
    "                        self.splitDataFile(self.m_NodeArray[nodeCount],data_left,data_right)\n",
    "\n",
    "                        self.m_CurrNodeNum = self.m_CurrNodeNum+2\n",
    "\n",
    "            else:\n",
    "                print(\"Tree Model Trained!!!!!!!!\")\n",
    "                break  \n",
    "\n",
    "    def predict(self,X_test):\n",
    "        pred = np.zeros((X_test.shape[0],1))\n",
    "        leaf_node_ls = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            nodeCount=0\n",
    "            x = X_test[i]\n",
    "            while(nodeCount < self.m_MaxNodeNum and self.m_NodeArray[nodeCount].m_IsDecisionNode == True):\n",
    "\n",
    "                if self.decisionRule(x,self.m_NodeArray[nodeCount])== 0:\n",
    "                    nodeCount = self.m_NodeArray[nodeCount].m_LeftChildIndx\n",
    "                else:\n",
    "                    nodeCount = self.m_NodeArray[nodeCount].m_RightChildIndx\n",
    "            y_pred = self.m_NodeArray[nodeCount].m_Label\n",
    "            pred[i][0] = y_pred\n",
    "            leaf_node_ls.append(nodeCount)\n",
    "        return(pred,leaf_node_ls)\n",
    "\n",
    "##################################################################################################################\n",
    "dataNumThresh = 35\n",
    "impThresh  = 0.01\n",
    "impDropThresh = 1e-5\n",
    "depth = 5\n",
    "method = 3\n",
    "path = os.getcwd()\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer(return_X_y=True)\n",
    "X = data[0]\n",
    "y = data[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
    "\n",
    "clf = C_Tree(depth,2**(depth+1)-1,path,dataNumThresh,impThresh,impDropThresh,method)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred,leaf_node_ls = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Means Tree Accuracy:  0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "print(\"Two-Means Tree Accuracy: \",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <center>Kernal-based Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianKernel(X_arr,X,X_central):\n",
    "    sig_arr = np.std(X_arr,axis=0)\n",
    "    sig_arr = np.ravel(sig_arr)\n",
    "    dist_sum = 0\n",
    "    for i in range(len(X)):\n",
    "        d1 = (X[i]-X_central[i])/sig_arr[i]\n",
    "        dist_sum += d1**2\n",
    "    kernel_val = np.exp(-0.5*dist_sum)\n",
    "    return(kernel_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernelbasedClassifier(X_test,leaf_node_ls):\n",
    "    y_pred = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        leaf_node_idx = leaf_node_ls[i]\n",
    "        node_file_name = \"d_\"+str(leaf_node_idx)+\".csv\"\n",
    "        node_data_arr = np.genfromtxt(node_file_name,delimiter=\",\")\n",
    "        X_node = node_data_arr[:,:-1]\n",
    "        y_node = node_data_arr[:,-1]\n",
    "        X = np.ravel(X_test[i,:])\n",
    "        sum_1 = 0\n",
    "        sum_2 = 0\n",
    "        for j in range(X_node.shape[0]):\n",
    "            X_central = np.ravel(X_node[j,:])\n",
    "            k = GaussianKernel(X_node,X,X_central)\n",
    "            sum_1 += k*y_node[j]\n",
    "            sum_2 += k\n",
    "        val = sum_1/sum_2\n",
    "        if val>0.5:\n",
    "            y_pred.append(1)\n",
    "        if val<=0.5:\n",
    "            y_pred.append(0)\n",
    "    return(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = kernelbasedClassifier(X_test,leaf_node_ls)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernal Based Classification Accuracy:  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "print(\"Kernal Based Classification Accuracy: \",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
